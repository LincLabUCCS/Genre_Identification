{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gutenberg Chapters Dataset with Hierarchical Attention Network (HAN)\n",
    "HAN analysis with the h2 hierarchical Gutenberg chapters dataset. Using the following configuration:\n",
    "1. Using Learned Embedding\n",
    "1. Term Embedding size: 100\n",
    "1. Sentence Embedding size: 200\n",
    "1. Document Embedding size: 300\n",
    "1. Top vocabulary count 5,000\n",
    "1. Adam Learning Rate of 1e-4\n",
    "1. Gradient Constraint: 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "ai_lit_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir, os.pardir))\n",
    "print(\"Loading AI Lit system from path\", ai_lit_path)\n",
    "sys.path.append(ai_lit_path)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from ai_lit.analysis import analysis_util\n",
    "from ai_lit.input.gutenberg_dataset import gb_input\n",
    "from ai_lit.university.gutenberg import gb_chap_han"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the flags imported from the univserity and the model to set the configuration\n",
    "tf.flags.FLAGS.epochs=10\n",
    "tf.flags.FLAGS.batch_queue_capacity=200\n",
    "\n",
    "dataset_wkspc = os.path.join(ai_lit_path, 'workspace', 'gb_input')\n",
    "training_wkspc = os.path.join(ai_lit_path, 'workspace', 'gutenberg_chapters')\n",
    "model_name = 'han_100-200-300'\n",
    "subjects = gb_input.get_subjects(dataset_wkspc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluation_name = 'standard_eval'\n",
    "univ = gb_chap_han.GbChaptersHANUniversity(model_name, training_wkspc, dataset_wkspc)\n",
    "accuracy, f1, cm = analysis_util.train_and_evaluate(univ, model_name, evaluation_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
